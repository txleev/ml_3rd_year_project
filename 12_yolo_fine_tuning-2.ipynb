{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e72197-c912-496f-9cc9-0b6b30318773",
   "metadata": {},
   "source": [
    "# Exercise ( Quiz 2.5p ): Simpsons Character Detection with YOLO\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üü® Exercise: Fine-tuning YOLO for Custom Object Detection\n",
    "\n",
    "üìå Objective:\n",
    "\n",
    "In this exercise, you will fine-tune a YOLO object detection model on a custom dataset with two classes:\n",
    "```\n",
    "\t‚Ä¢\tbart simpson\n",
    "\t‚Ä¢\thomer simpson\n",
    "```\n",
    "\n",
    "After training the model, you will apply it to a video to detect and label these characters in real-time.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üóÇ Dataset:\n",
    "\n",
    "You are provided with a YOLO-compatible dataset that includes:\n",
    "```\n",
    "\t‚Ä¢\ttrain/images/ ‚Äì folder with training and validation images\n",
    "\t‚Ä¢\ttrain/labels/ ‚Äì YOLO-format text files with bounding box annotations\n",
    "\t‚Ä¢\tdata.yaml ‚Äì configuration file listing class names and dataset paths\n",
    "```\n",
    "Classes:\n",
    "\n",
    "`names: ['bart simpson', 'homer simpson']`\n",
    "\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üõ†Ô∏è Task Steps:\n",
    "```\n",
    "1.\tSet up the YOLO environment:\n",
    "\t‚Ä¢\tUse YOLOv11 (or YOLOv8)\n",
    "\t‚Ä¢\tEnsure all dependencies are installed (torch, opencv-python, etc.).\n",
    "2.\tTrain the model:\n",
    "\t‚Ä¢\tFine-tune YOLO on the provided dataset.\n",
    "\t‚Ä¢\tSet appropriate parameters such as img-size, batch-size, epochs, and device.\n",
    "\t‚Ä¢\tSave the best-performing weights.\n",
    "3.\tApply the model to video detection:\n",
    "\t‚Ä¢\tLoad the trained model.\n",
    "\t‚Ä¢\tProcess the provided video file frame-by-frame.\n",
    "\t‚Ä¢\tApply the model and visualize bounding boxes with labels (bart simpson or homer simpson).\n",
    "\t‚Ä¢\tSave or display the output video with detection.\n",
    "```\n",
    "‚∏ª\n",
    "\n",
    "üéØ Deliverables:\n",
    "```\n",
    "1.\tTrained model weights (best.pt)\n",
    "2.\tPython script or Jupyter notebook for:\n",
    "\t‚Ä¢\tTraining code\n",
    "\t‚Ä¢\tInference on the video with object detection output\n",
    "3.\tOutput video file showing the detection results\n",
    "```\n",
    "‚∏ª\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de724ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"simpsons_images/data.yaml\",\n",
    "    epochs=25,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    device=0,  # –∏–ª–∏ \"cpu\" –µ—Å–ª–∏ –Ω–µ—Ç GPU\n",
    "    name=\"yolov8_bart_homer\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6b21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.version.cuda)  # Shows the CUDA version PyTorch is using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d52ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(\"runs/detect/yolov8_bart_homer/weights/best.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "out = cv2.VideoWriter(\"output_detected_fix.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.predict(source=frame, conf=0.25, save=False)\n",
    "\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    out.write(annotated_frame)\n",
    "    cv2.imshow(\"Detection\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04fb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a538f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d850cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17eaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c51d7e-8904-4e08-83ae-2e1b4863174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75877579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09376f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fafd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (YOLO)",
   "language": "python",
   "name": "yolo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
